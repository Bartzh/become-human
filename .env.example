# 若要使用的openai（兼容）模型服务的api key
OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxx

# 若要使用的openai（兼容）模型服务地址
OPENAI_API_BASE=https://xxxxxxxxxxxxx/compatible-mode/v1

# 若要使用的dashscope模型服务的api key
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxx

# 若要使用的dashscope模型服务地址（海外为https://dashscope-intl.aliyuncs.com/compatible-mode/v1）
DASHSCOPE_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1

# 聊天模型名称。格式必须为 {服务提供商}:{模型名称}
CHAT_MODEL_NAME=dashscope:deepseek-v3.2

# 聊天模型是否启用思考（对于如qwen3，deepseek-v3.1及以上等模型）
CHAT_MODEL_ENABLE_THINKING=true

# 结构化输出模型名称。格式必须为 {服务提供商}:{模型名称}
STRUCTURED_MODEL_NAME=dashscope:qwen3-max

# 结构化输出模型是否启用思考（对于如qwen3，deepseek-v3.1及以上等模型）
STRUCTURED_MODEL_ENABLE_THINKING=false

# embedding模型名称。格式必须为 {服务提供商}:{模型名称}
# embedding模型是必须的，且模型需要输出归一化向量，支持cosine计算
EMBEDDING_MODEL_NAME=dashscope:text-embedding-v4


# 如果没有QIANFAN_API_KEY，会使用这个模型用作AI搜索。需要设置DASHSCOPE_API的KEY和BASE，只能使用其平台上支持enable_search的模型
DASHSCOPE_SEARCH_MODEL_NAME=qwen3-max

# 若要使用传统百度搜索，请设置这个变量
QIANFAN_API_KEY=bce-xxxxxxxxxxxxxxxx


# 启用的记忆类型（默认全部启用，不建议修改）
MEMORY_TYPES=original, episodic, reflective


# 用户名（对于main.py的终端来说）
USER_NAME=User


# app.py的jwt编解码密钥
APP_PRIVATE_KEY=become-human

# app.py的端口
APP_PORT=36262

# app.py的host
APP_HOST=localhost


# LangSmith
LANGSMITH_TRACING=false
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
LANGSMITH_PROJECT="become-human"
